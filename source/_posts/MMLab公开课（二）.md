---
title: OpenMMLab 实战营打卡 - 第 2 课
author: Luo Tian
date: 2023-02-03 17:38:00
tags:
- MMLab
categories:
- MMLab
top_img: /img/MMlab.jpg
summary:
top:
cover: /img/MMlab.jpg
coverImg:

---

**图像分类基础与 MMCls**

## 图像分类概述

&#8195;&#8195;图像分类问题就是构建一个可实现的计算函数$F:\mathbb{R} ^{H\times W\times 3}\rightarrow \left\{ 1,\cdots ,K \right\} $，且预测结果符合人类认知。但是难点就是图像内容是像素整体呈现出来的结果，和个别像素没有直接的关联，难以设计具体的算法实现。于是需要需要让机器从数据中学习。而机器学习也是有局限的，机器学习算法善于处理低维、分布相对简单的数据，而对于几十万维的复杂数据处理优势就不足了。我们需要更好的图像分类方法。

#### 特征工程

&#8195;&#8195;在 90 年代，人们用计算梯度直方图 (Histogram of Oriented Gradients) 等一些人工算法将图片映射成相对低维的特征向量，这样极大的简化了数据的表达，同时也保留了内容相关的信息，使得机器学习得以处理图像分类问题。
&#8195;&#8195;但是这些也只是特征工程 + 机器学习算法实现图像分类，性能和效果还有很大的提升。
![特征工程](/img/MMlab/8.png)

#### 特征学习

&#8195;&#8195;之后人们开始探索从特征工程到特征学习的转变，特征学习其实也就是学习如何产生适合分类的特征，将多个简单特征变换复合构成一个复杂的端到端分类器。这样一来使得图像的分类精度得到进一步的提高。
![特征学习](/img/MMlab/9.png)

#### 深度学习

&#8195;&#8195;在 2012 年的竞赛中，来自多伦多大学的团队首次使用**深度学习方法AlexNet**，一举将错误率降低至 15.3% ，而传统视觉算法的性能已经达到瓶颈。到了 2015 年，卷积网络的性能已经远超传统方法。
![深度学习](/img/MMlab/10.png)

## 卷积神经网络

### 模型发展概况

&#8195;&#8195;图像分类 & 视觉基础模型的发展概况如下图所示：
![深度学习模型发展概况](/img/MMlab/18.png)

### 一些基础卷积神经网络模型介绍

#### AlexNet

*2012*
&#8195;&#8195;该模型是第一个成功实现大规模图像的模型，在 ImageNet 数据集上达到 ~85% 的准确率。一共有 5 个卷积层，3 个全连接层，60M 个可学习的参数。模型使用了 ReLU 激活函数，大幅提高了收敛速度。最重要的是它实现并开源了 cuda-convnet ，使在工程上用 GPU 上训练大规模神经网络成为可能。
![AlexNet](/img/MMlab/11.png)

#### Going Deeper

*2012~2014*

#### VGG

*2014*
&#8195;&#8195;该模型将大尺寸的卷积拆解为多层$3\times 3$的卷积，具有 138M 个权重参数。虽然和大卷积核具有相同的感受野，但是具有更少的参数量、更多的层数和表达能力。3x3 卷积可以配合 1 像素的边界填充，维持空间原本的分辨率，具有更好的适用性。
&#8195;&#8195;该网络每隔几层倍增通道数、减半分辨率，生成 1/2、1/4 尺度的更高抽象层级的特征。不同层次的特征在尺寸上有简单的比例关系，方便在位置敏感的下游任务中使用，如检测、分割等。
![VGG](/img/MMlab/12.png)

#### GoogleNet

*2014*
&#8195;&#8195;该模型使用 Inception 模块堆叠形成，22 个可学习层和仅 7M 的权重参数。最后的分类仅使用单层全连接层，可节省大量参数。
![GoogleNet](/img/MMlab/13.png)

#### ResNet

*V1 2015*
&#8195;&#8195;模型的层数达到一定的程度的时候，正确率会不增反降。因为随着层数的不断加深，深层网络有潜力达到更高的精度，但是常规的优化算法难以找到这个更优的模型。
&#8195;&#8195;我们知道卷积退化为恒等映射的时候，深层网络就会回退到浅层网络，因此我们可以让新增加的卷积层拟合一个近似恒等映射，恰好可以进行进一步的优化。
&#8195;&#8195;基于上述实验现象，便有了残差建模以及残差网络：
&#8195;&#8195;**残差建模**就是让新增加的层拟合浅层网络与深层网络之间的差异，使得模型更容易学习。在这里梯度可以直接回传到浅层网络以监督浅层网络的学习，同时没有引入额外参数，让参数更有的效贡献到最终的模型中。
![残差学习的基本思路](/img/MMlab/14.png)
&#8195;&#8195;**残差网络**以 VGG 为基础，保持多级结构，并增加层数和跨层连接。每级输出分辨率减半，通道倍增，并且全局平均池化压缩空间维度。
![残差网络特性](/img/MMlab/15.png)
&#8195;&#8195;**ResNet** 是多个深浅模型的集成，其中的残差链接让损失曲面更光滑，更容易收敛得到局部或全局最优解。以 ResNet-34 (34 层  ImageNet Top-5) 为例，每级包含若干残差模块，不同残差模块个数不同。如图所示：
![ ResNet-34](/img/MMlab/16.png)
&#8195;&#8195;ResNet 使用两种残差模块，分别为 Basic block 和 Bottleneck block ，Basic block 用于 ResNet-18 和 34，Bottleneck block 用于 ResNet-50 、101 和 152 ，其中 1x1 卷积用于压缩通道，降低计算开销。
![ResNet中两种残差模块](/img/MMlab/17.png)
&#8195;&#8195;ResNet 后续也推出了许多优化版本：
- **ResNet B/C/D**：残差模块的局部改进
- **ResNeXt**：使用分组卷积，降低参数量
- **SEResNet**：在通道维度引入注意力机制

### 更强的图像分类模型

#### NAS

*2016+*
&#8195;&#8195;NAS 全称为神经结构搜索（Neural Architecture Search），代表工作有：NASNet (2017) 、MnasNet (2018) 、EfficientNet (2019) 、RegNet (2020)等。例如 NASNet 使用一个 RNN 预测网络模块和连接方式，使用强化学习方法优化 RNN 使之预测最佳结构。

#### Vision Transformers

*2020+*
&#8195;&#8195;该模型使用 Transformer 替代卷积网络实现图像分类，使用更大的数据集训练，达到超越卷积网络的精度。代表工作有：Vision Transformer (2020) ，Swin-Transformer (2021ICCV 最佳论文)。

#### ConvNeXt

*2022*
&#8195;&#8195;该模型将 Swin Transformer 的模型元素迁移到卷积网络中，性能反超 Transformer 。

### 轻量化卷积神经网络介绍





>第二课的知识点比较密集，需要再整理一下，后续会继续进行发布！*QAQ*